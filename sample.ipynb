{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b40fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d26ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import chromadb\n",
    "from docling.document_converter import DocumentConverter\n",
    "from langchain_text_splitters import (\n",
    "    MarkdownHeaderTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import chromadb\n",
    "from docling.document_converter import DocumentConverter\n",
    "from langchain_text_splitters import (\n",
    "    MarkdownHeaderTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class PolicyIngestionPipeline:\n",
    "    def __init__(self, pdf_dir: str, db_dir: str):\n",
    "        self.pdf_dir = Path(pdf_dir)\n",
    "        self.db_dir = Path(db_dir)\n",
    "        \n",
    "        # 1. Initialize the Parsers\n",
    "        self.converter = DocumentConverter()\n",
    "        \n",
    "        # Define which markdown headers we want to split on\n",
    "        headers_to_split_on = [\n",
    "            (\"#\", \"Header_1\"),\n",
    "            (\"##\", \"Header_2\"),\n",
    "            (\"###\", \"Header_3\"),\n",
    "        ]\n",
    "        self.markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "            headers_to_split_on=headers_to_split_on, strip_headers=False\n",
    "        )\n",
    "        \n",
    "        # Fallback character splitter: In case a single section under a header is massively long\n",
    "        self.fallback_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=600, \n",
    "            chunk_overlap=100\n",
    "        )\n",
    "\n",
    "        # 2. Initialize the Embedding Model\n",
    "        # BAAI/bge-small-en-v1.5 is extremely fast locally and highly ranked for retrieval\n",
    "        print(\"Loading embedding model...\")\n",
    "        self.embedding_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "        # 3. Initialize Persistent ChromaDB\n",
    "        self.chroma_client = chromadb.PersistentClient(path=str(self.db_dir))\n",
    "        self.collection = self.chroma_client.get_or_create_collection(\n",
    "            name=\"corporate_policies\",\n",
    "            metadata={\"hnsw:space\": \"cosine\"} # Optimize for cosine similarity\n",
    "        )\n",
    "\n",
    "    def process_all_pdfs(self):\n",
    "        \"\"\"Finds all PDFs in the target directory and processes them.\"\"\"\n",
    "        pdf_files = list(self.pdf_dir.glob(\"*.pdf\"))\n",
    "        if not pdf_files:\n",
    "            print(f\"No PDFs found in {self.pdf_dir}\")\n",
    "            return\n",
    "\n",
    "        for pdf_path in pdf_files:\n",
    "            print(f\"\\nProcessing: {pdf_path.name}\")\n",
    "            self._process_single_pdf(pdf_path)\n",
    "            \n",
    "        print(\"\\nâœ… All documents ingested successfully!\")\n",
    "\n",
    "    def _process_single_pdf(self, pdf_path: Path):\n",
    "        # Step 1: Convert PDF to Markdown using Docling\n",
    "        print(\"  -> Converting to Markdown...\")\n",
    "        result = self.converter.convert(pdf_path)\n",
    "        markdown_text = result.document.export_to_markdown()\n",
    "\n",
    "        # Step 2: Semantic Split by Headers\n",
    "        print(\"  -> Chunking by semantic headers...\")\n",
    "        header_splits = self.markdown_splitter.split_text(markdown_text)\n",
    "\n",
    "        # Step 3: Apply fallback splitting to oversized sections and prepare data\n",
    "        final_chunks = []\n",
    "        final_metadatas = []\n",
    "        final_ids = []\n",
    "\n",
    "        for i, split in enumerate(header_splits):\n",
    "            # If the section is too large, break it down further\n",
    "            sub_chunks = self.fallback_splitter.split_text(split.page_content)\n",
    "            \n",
    "            for j, sub_chunk in enumerate(sub_chunks):\n",
    "                final_chunks.append(sub_chunk)\n",
    "                \n",
    "                # Combine original document metadata with the extracted header metadata\n",
    "                meta = split.metadata.copy()\n",
    "                meta[\"source_file\"] = pdf_path.name\n",
    "                final_metadatas.append(meta)\n",
    "                \n",
    "                # Create a unique ID for the vector database\n",
    "                final_ids.append(f\"{pdf_path.stem}_chunk_{i}_{j}\")\n",
    "\n",
    "        # Step 4: Generate Embeddings\n",
    "        print(f\"  -> Generating embeddings for {len(final_chunks)} chunks...\")\n",
    "        embeddings = self.embedding_model.encode(final_chunks).tolist()\n",
    "\n",
    "        # Step 5: Store in ChromaDB\n",
    "        print(\"  -> Storing in ChromaDB...\")\n",
    "        self.collection.upsert(\n",
    "            documents=final_chunks,\n",
    "            embeddings=embeddings,\n",
    "            metadatas=final_metadatas,\n",
    "            ids=final_ids\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
